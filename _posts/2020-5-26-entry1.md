---
layout: post
title: Machine learning is helpful to psychology, conditions apply
---

The paper to be reviewed is “Machine learning and psychological research: The unexplored effect of measurement” by Jacobucci & Grimm, published at Perspectives on Psychological Science in 2020. The authors pointed out the previously overlooked effect of measurement errors when using machine learning techniques to find non-linear relationships. 

<details><summary>SEE MORE</summary>
<p>
	
	The field of artificial intelligence is moving forward in a speed faster than ever, and with that, other field such as medicine are benefiting from the developments in AI. One important such benefit is the use of machine learning in analyzing complex and interactive data. However, on average, psychology has not seen superior performance of ML algorithms (Jie, Collins, Steyerberg, Verbakel, & van Calster, 2019), which is unexpected given the plenty of interactive predictor variables in the field. The authors argued that the imprecise measurements may be partially responsible for the lack of improvement. <br />
	
	To demonstrate their points, the authors simulated a non-linear relationship between x and y with interaction terms and non-linear operations. There was also a linear relationship as a control. They then used both ML and linear regression model to fit both sets of data. Instead of inputting the precise predictor values, the authors artificially implemented measurement errors of various levels. In real life situations, these could stand for inaccurate apparatus, imprecise choices, and/or random guessing etc. They found that as expected, the linear regression model was better for linear relationships, and the ML model was better for non-linear relationships when the measurement errors were low. When the measurement errors were high, both models accounted for less variance of the data. Importantly, when comparing the two models, the linear regression fitted both linear and non-linear relationships better. This experiment showcased the importance of feeding accurate data to ML algorithms. When the input data lack reliability, even an inappropriate model (i.e. using a linear model for non-linear relationships) could fit better than ML models. <br />
	
	The current paper simulated the non-linear relationship with both non-linear operations (e.g. sin x) and interaction terms (e.g. x*y). The later is probably more prevalent in the realm of psychology and neuroscience. One remaining question I have after reading the paper is whether measurement errors may affect ML performance in modeling the two type of non-linearity the same. (Or perhaps the two types are mathematically equivalent, and I just didn’t know it). <br />
	
	In conclusion, this experiment could serve as a reminder for someone like me, who have been a long time consumer of AI related news and YouTube videos, but only recently started to systematically learn about AI/ML and tried to apply these techniques to my own research projects. Despite all those news reports showing how AI could play games, recognize pictures, and perhaps perform operations better than human, it is not the answer to every data science problem. This experiment also speaks to the benefit of seeking converging evidence. With only one technique, it may be hard to quantitatively assess the level of reliability in our data. When coupled with multiple ways to measure the same variable, we could better calculate reliability and get more accurate results. <br />	
	
</p>
</details>
