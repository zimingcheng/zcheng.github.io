---
layout: post
title: Machine learning is helpful to psychology, conditions apply
---

Today I will bring you the debate between Anthony Zador and Timothy Lillicrap as a part of the [NeuroMatch conference](https://www.crowdcast.io/e/neuromatch2/3), on the relative importance of innate structure and learning algorithms in artificial neural networks (ANN) research. The current focus of ANN has been on learning, defined as the process of specifying huge weight matrices from big training datasets. Lillicrap argued that the current method has produced numerous promising results, and will continue to do so when facing more real-life problems. On contrary, Zador argued that the importance of innate structures without learning has been underappreciated in AI research, and needs to be more studied if we wish to have AIs capable of doing real world (esp. sensorimotor) tasks. 

Lillicrap
------
In favour of the importance of learning, Lillicrap argued that learning does the bulk of information processing in biological intelligence, especially when the tasks are flexible and high-level. Importantly, the result of learning could even overcome the preset innate structure, as evident from neural plasticity studies. For example, the innately defined visual brain area could be repurposed with the lack of visual input data when the person unfortunately is/becomes blind. As someone in the field of AI, Lillicrap then clarified that unlike a common belief in the neuroscience community, machine learning can do much more than ImageNet. He took AlphaStar, an AI trained to play real-time strategy game StarCraft, as an example. Prior to the success of the project, many have argued that ANN would be ill-posed to solve problems involving partial information and continuous time, both of which were integral parts of StarCraft. In the end, ANN could get the job done with the appropriate input data and loss functions etc. Overall, Lillicrap expressed his faith that ANN could continue to achieve what some may consider impossible. 

Zador
------
Zador took a more philosophical approach and argued for the importance of innate structures. He started by the observation that in the biological world, most animal behaviours are not learned but innate. For example, the rat pupâ€™s hippocampus already had rudimentary place cell structure before it could leave its cave. The innate structures that are built-in on the genome by evolution can result in our unconscious intelligent behaviours, which may seem easy but only because we have mastered it so much. Its implication in building a general strong AI is that it is hard to get the unconscious rat part right (which took evolution 700 million years), but would be relatively much easier to move from rat AI to human AI (which too evolution 70 million years) once we have the foundation on innate structures. A real example of such innate structure is convolution neural network (CNN), which loosely models the structure of the ventral visual stream. Moreover, there has been initial success in Zador lab to model the role of evolution on the brain, in which the connectome is first compressed in a way similar to proteins to genome, and then unpacked in the next generation. Following this, he argued that learning could potentially be divided into an inner loop within individuals as the learning we currently use, and an outer loop across generations describing optimization by evolution. Focusing only on the former half would miss out on how humans learn. Relating to this, an audience flashed out an interesting idea that perhaps we could look at the learning process of individual AI algorithms as the inner loop learning, and scientists goal of building more powerful AI algorithms as the outer loop learning.

Discussion
------
There has been several interesting back-and-forth between the debaters. An interesting one is the dishwashing robot argument. Zador first argued that the current learning-centered AIs could not achieve the mostly unconscious sensorimotor activities, such as loading a dishwasher. Lillicrap responded saying that this is perhaps because no data was collected on dishwashing, and that he believes there could be a dishwashing AI if we carefully measure the arm positions and plate positions etc. to come up with the right reward and cost function. 

Overall, I would tend to agree with Zador that we should focus more on innate structures in future AI researches. One of my current projects show that a computational model inspired by the pattern completion and pattern separation processes in the hippocampus could indeed predict human learning outcomes. 

